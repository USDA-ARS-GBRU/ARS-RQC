#!/usr/bin/env python3
# rqcparser.py - A module for parsing files generated by rqcfilter
# Adam Rivers 02/2017 USDA-ARS-GBRU

import json
import pandas as pd
import numpy as np
import tempfile
import os
from ars_rqc.definitions import ROOT_DIR
from collections import OrderedDict
def _header_lines(file, symbol='#'):
    """returns number of header lines at the beginning of a file"""
    try:
        with open(file, 'r') as f:
            lc = 0
            for line in f:
                if line.startswith(symbol):
                    lc += 1
                else:
                    return lc
    except IOError:
        print("could not open file {}".format(file))


def _remove_percent(llist):
    """removes percent signs from the end of items in list and retuns list"""
    # this removes the percent signs from columns
    try:
        ll = []
        for item in llist:
            if isinstance(item, str):
                if item.endswith('%'):
                    ll.append(item[:-1].strip())
                else:
                    ll.append(item)
            else:
                ll.append(item)
        return ll
    except RuntimeError:
        print("could not remove percentages frome some columns, returning the \
              origional list")
    return llist


def parser_1(file):
    """Converts tabular files with one header line preceded by a # to a
    pandas dataframe then returns a dictionary of that dataframe"""
    try:
        f = os.path.abspath(file)
        dta = pd.read_csv(f, sep="\t")
        # Trim off leading #, if present
        if dta.columns[0].startswith('#'):
            dta.rename(columns={dta.columns[0]: dta.columns[0][1:]},
                       inplace=True)
        d = dta.to_dict()
        return OrderedDict(sorted(d.items(), key=lambda t: t[0]))
    except RuntimeError:
        print("could not parse the file {}".format(file))


def parser_2(file):
    """Converts files with preliminary lines of key-value data
    prefixed by a # followed by one header line preceded by a #, followed by
    tabular data. converts tabular data to pandas dataframe then returns a
    a dictionary of the key value data and the dataframe"""
    try:
        f = os.path.abspath(file)
        hlines = _header_lines(f)  # Count number of header lines
        ddict = {}  # Create temporary dictionary
        tf = tempfile.NamedTemporaryFile(delete=False, mode='w')
        with open(f, 'r') as d1:  # Open the data file
            for n, line in enumerate(d1):  # Read and count lines
                if n < (hlines - 1):
                    llist = line.strip().split('\t')
                    ll = _remove_percent(llist)
                    try:
                        if len(ll) == 2:
                                cleankey = ll[0][1:]
                                ddict[cleankey] = ll[1]
                    except RuntimeError:
                        print("parser 2 failed: There were not two columns in \
                              line {}".format(str(n+1)))
                else:
                    tf.write(line)
        fname = tf.name
        tf.close()
        ddict['dataframe'] = parser_1(fname)
        return ddict
    except RuntimeError:
        print("Could not parse file {}".format(file))
    finally:
        os.remove(fname)


def parser_3(file):
    """Converts bbduk scaffold report files ot dictionaries"""
    try:
        f = os.path.abspath(file)
        hlines = _header_lines(f)  # Count number of header lines
        ddict = {}  # Create temporary dictionary
        tf = tempfile.NamedTemporaryFile(delete=False, mode='w')
        with open(f, 'r') as d1:  # Open the data file
            for n, line in enumerate(d1):  # Read and count lines
                ll = line.strip().split('\t')
                if n == 0:
                    continue
                if n == 1:
                    ddict["TotalReads"] = ll[1]
                    if len(ll) == 3:
                        ddict["TotalBases"] = ll[2]
                elif n == 2:
                    ddict["ReadsMatched"] = ll[1]
                    ddict["PctReadsMatched"] = ll[2]
                elif n >= 3:
                    tf.write(line)
        fname = tf.name
        tf.close()
        ddict['dataframe'] = parser_1(fname)
        return ddict
    except RuntimeError:
        print("Could not parse file {}".format(file))
    finally:
        os.remove(fname)


def parser_4(file):
    with open(os.path.abspath(file), 'r') as f:
        value = f.readline().strip()
        pname = os.path.basename(file).split(".")[0]
        return {pname: value}


def _select_pfunc(file):
    try:
        fbase = os.path.basename(file)
        with open(os.path.join(ROOT_DIR, 'data', 'parameters.json'), 'r') as p:
            fastq_parameters = json.load(p)
            if fbase in fastq_parameters["parser"]:
                pfunc = fastq_parameters["parser"][fbase]
                return pfunc
            else:
                return None
    except IOError:
        print("Could not determine the correct parsing function to use for the \
              file {}. Check the paramaters.json file".format(file))


def parse_dir(dir):
    """ takes a file path looks the file name up in the parameters file and \
    returns a dataframe"""
    bname = os.path.basename(dir)
    print(bname)
    ddict = {}
    for file in os.listdir(dir):
        ffile = os.path.join(dir, file)
        try:
            pfunc = _select_pfunc(ffile)
            if pfunc:
                command = str(pfunc) + '("' + str(ffile) + '")'
                result = eval(command)
                ddict[file] = result
            else:
                print ("skipping file {}".format(ffile))
                continue
        except IOError:
            print("could not parse file {}".format(ffile))
            continue
    return ddict
