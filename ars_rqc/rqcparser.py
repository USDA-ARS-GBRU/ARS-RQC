#!/usr/bin/env python3
# rqcparser.py - A module for parsing files generated by rqcfilter
# Adam Rivers 02/2017 USDA-ARS-GBRU

import pandas as pd
import json
import numpy as np
import os
from ars_rqc.definitions import ROOT_DIR


def _header_lines(file, symbol='#'):
    """returns number of header lines at the beginning of a file"""
    try:
        with open(file, 'r') as f:
            lc = 0
            for line in f:
                if line.startswith(symbol):
                    lc += 1
                else:
                    return lc
    except IOError:
        print("could not open file {}".format(file))


def _remove_percent(llist):
    """removes percent signs from the end of items in list and retuns list"""
    # this removes the percent signs from columns
    try:
        ll = []
        for item in llist:
            if isinstance(item, str):
                if item.strip().endswith('%'):
                    ll.append(item.strip()[:-1])
                else:
                    ll.append(item)
            else:
                ll.append(item)
        return ll
    except RuntimeError:
        print("could not remove percentages frome some columns, returning the \
              origional list")
    return llist


def _parser_1(file):
    """Takes a file awith any number of # commented lines followed by \
    a header line with a leading # and returns a dictionary containing a pandas
    dataframe"""
    try:
        f = os.path.abspath(file)
        hlines = _header_lines(f)
        dta = pd.read_csv(f, sep="\t", skiprows=hlines-1, comment=None)
        if dta.columns[0].startswith('#'):
            dta = dta.rename(index=str, columns={dta.columns[0]: dta.columns[0][1:]})
        return {"dataframe": dta}
    except RuntimeError:
        print("could not parse the file {}".format(file))


def _parser_2(file):
    """Reads files with preliminary lines of key-value data
    prefixed by a # followed by one header line preceded by a #, followed by
    tabular data. Converts tabular data to pandas dataframe then returns a
    a dictionary with the key-value data and a pandas dataframe"""
    try:
        f = os.path.abspath(file)
        hlines = _header_lines(f)  # Count number of header lines
        ddict = {}  # Create temporary dictionary
        with open(f, 'r') as d1:  # Open the data file
            for n, line in enumerate(d1):  # Read and count lines
                if n < (hlines - 1):
                    llist = line.strip().split('\t')
                    ll = _remove_percent(llist)
                    try:
                        if len(ll) == 2:
                                cleankey = ll[0][1:]
                                ddict[cleankey] = ll[1]
                    except RuntimeError:
                        print("parser 2 failed: There were not two columns in \
                              line {}".format(str(n+1)))
                else:
                    break
        dataframe = _parser_1(file)["dataframe"]
        return {"desc": ddict, "dataframe": dataframe}
    except RuntimeError:
        print("Could not parse file {}".format(file))


def _parser_3(file):
    """Converts bbduk filter contaminants scaffold report files to a dictionary
    containing descriptive statistics and a pandas dataframe"""
    try:
        f = os.path.abspath(file)
        hlines = _header_lines(f)  # Count number of header lines
        ddict = {}  # Create temporary dictionary
        with open(f, 'r') as d1:  # Open the data file
            for n, line in enumerate(d1):  # Read and count lines
                llist = line.strip().split('\t')
                ll = _remove_percent(llist)
                print(ll)
                if n == 0:
                    continue
                if n == 1:
                    ddict["TotalReads"] = ll[1]
                    ddict["TotalBases"] = ll[2]
                elif n == 2:
                    ddict["ReadsMatched"] = ll[1]
                    ddict["PctReadsMatched"] = ll[2]
                else:
                    break
        dataframe = _parser_1(file)["dataframe"]
        dataframe.ReadsPct = pd.to_numeric(dataframe.ReadsPct.str.strip("%"))
        dataframe.BasesPct = pd.to_numeric(dataframe.BasesPct.str.strip("%"))
        return {"desc": ddict, "dataframe": dataframe}
    except RuntimeError:
        print("Could not parse file {}".format(file))

def _parser_4(file):
    """Converts bbduk trim adaptor report files to a dictionary containing
    descriptive statistics and a pandas dataframe"""
    try:
        f = os.path.abspath(file)
        hlines = _header_lines(f)  # Count number of header lines
        ddict = {}  # Create temporary dictionary
        with open(f, 'r') as d1:  # Open the data file
            for n, line in enumerate(d1):  # Read and count lines
                llist = line.strip().split('\t')
                ll = _remove_percent(llist)
                print(ll)
                if n == 0:
                    continue
                if n == 1:
                    ddict["TotalReads"] = ll[1]
                elif n == 2:
                    ddict["ReadsMatched"] = ll[1]
                    ddict["PctReadsMatched"] = ll[2]
                else:
                    break
        dataframe = _parser_1(file)["dataframe"]
        dataframe.ReadsPct = pd.to_numeric(dataframe.ReadsPct.str.strip("%"))
        return {"desc": ddict, "dataframe": dataframe}
    except RuntimeError:
        print("Could not parse file {}".format(file))


def _parser_5(file):
    with open(os.path.abspath(file), 'r') as f:
        value = f.readline().strip()
        pname = os.path.basename(file).split(".")[0]
        return {"desc": {pname: value}}


def _select_pfunc(file):
    try:
        fbase = os.path.basename(file)
        with open(os.path.join(ROOT_DIR, 'data', 'parameters.json'), 'r') as p:
            fastq_parameters = json.load(p)
            if fbase in fastq_parameters["parser"]:
                pfunc = fastq_parameters["parser"][fbase]
                return "_" + str(pfunc)
            else:
                return None
    except IOError:
        print("Could not determine the correct parsing function to use for the \
              file {}. Check the paramaters.json file".format(file))


def parse_dir(dir):
    """ takes a file path looks the file name up in the parameters file and \
    returns a dataframe"""
    bname = os.path.basename(dir)
    print(bname)
    ddict = {}
    for root, dirs, files in os.walk(dir, topdown=False):
        for name in files:
            filepath = (os.path.join(root, name))
            try:
                pfunc = _select_pfunc(name)
                if pfunc:
                    command = str(pfunc) + '("' + str(filepath) + '")'
                    result = eval(command)
                    ddict[name] = result
                    print("processing file {}".format(filepath))
                else:
                    print ("skipping file {}".format(filepath))
                    continue
            except IOError:
                print("could not parse file {}".format(filepath))
                continue
    return ddict
